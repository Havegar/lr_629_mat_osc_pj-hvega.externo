{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fbb18d-f5ea-4f2f-bcb5-760ac1081013",
   "metadata": {},
   "source": [
    "## Apiux & SII: calculo de indice de materia oscura en personas juridicas.\n",
    "## ATENCION: proyecto sujeto a mantenimiento continuo. \n",
    "\n",
    "## Henry Vega (henrry.vega@api-ux.com)\n",
    "## Data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bff1a6-1471-4b1a-98af-c1bcd085cf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark\n",
    "#warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0045495f-27ec-47ad-8474-dd42b9352a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/24 15:47:59 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "24/01/24 15:47:59 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "Setting spark.hadoop.yarn.resourcemanager.principal to hvega.externo\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/24 15:47:59 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "24/01/24 15:47:59 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "24/01/24 15:47:59 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "24/01/24 15:48:00 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:00 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:01 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:01 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:02 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:02 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:03 WARN HadoopFSDelegationTokenProvider: Token ABFS/IDBroker has not set up issue date properly. (provided: 0) Using current timestamp (1706111283058) as issue date instead. Consult token implementor to fix the behavior.\n",
      "24/01/24 15:48:03 WARN HadoopFSDelegationTokenProvider: Token ABFS/IDBroker has not set up issue date properly. (provided: 0) Using current timestamp (1706111283061) as issue date instead. Consult token implementor to fix the behavior.\n",
      "24/01/24 15:48:03 WARN HiveServer2CredentialProvider: Failed to get HS2 delegation token\n",
      "java.util.NoSuchElementException: spark.sql.hive.hiveserver2.jdbc.url\n",
      "\tat org.apache.spark.SparkConf.$anonfun$get$1(SparkConf.scala:245)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.SparkConf.get(SparkConf.scala:245)\n",
      "\tat com.hortonworks.spark.deploy.yarn.security.HiveServer2CredentialProvider.obtainDelegationTokens(HiveServer2CredentialProvider.scala:64)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.$anonfun$obtainDelegationTokens$2(HadoopDelegationTokenManager.scala:164)\n",
      "\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:213)\n",
      "\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)\n",
      "\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)\n",
      "\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.org$apache$spark$deploy$security$HadoopDelegationTokenManager$$obtainDelegationTokens(HadoopDelegationTokenManager.scala:162)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anon$4.run(HadoopDelegationTokenManager.scala:226)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anon$4.run(HadoopDelegationTokenManager.scala:224)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.obtainTokensAndScheduleRenewal(HadoopDelegationTokenManager.scala:224)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.org$apache$spark$deploy$security$HadoopDelegationTokenManager$$updateTokensTask(HadoopDelegationTokenManager.scala:198)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.start(HadoopDelegationTokenManager.scala:123)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.$anonfun$start$1(CoarseGrainedSchedulerBackend.scala:552)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.$anonfun$start$1$adapted(CoarseGrainedSchedulerBackend.scala:549)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.start(CoarseGrainedSchedulerBackend.scala:549)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.KubernetesClusterSchedulerBackend.start(KubernetesClusterSchedulerBackend.scala:95)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:220)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:581)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:03 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:03 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:04 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:04 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/01/24 15:48:05 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Test\")  \\\n",
    "  .config(\"spark.yarn.access.hadoopFileSystems\",\"abfs://data@datalakesii.dfs.core.windows.net/\") \\\n",
    "  .config(\"spark.executor.memory\", \"24g\") \\\n",
    "  .config(\"spark.driver.memory\", \"12g\")\\\n",
    "  .config(\"spark.executor.cores\", \"12\") \\\n",
    "  .config(\"spark.executor.instances\", \"24\") \\\n",
    "  .config(\"spark.driver.maxResultSize\", \"12g\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f0dad-7108-42cf-82fe-36df09d3dd52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Carga de relaciones societarias(depurada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efab72-f268-4525-b3f7-d1cebacc74c1",
   "metadata": {},
   "source": [
    "Se carga la data depurada anteriormente de relaciones societarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2692b3e0-49ff-419d-98a4-93624ef9de61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/24 15:48:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:49:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:49:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:49:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:49:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:50:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:50:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:50:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:50:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:51:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:51:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:51:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:51:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:52:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:52:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:52:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:52:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:53:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:53:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:53:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:53:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:54:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:54:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:54:31 WARN WatcherWebSocketListener: Exec Failure javax.net.ssl.SSLException Connection reset\n",
      "24/01/24 15:54:32 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed (this is expected if the application is shutting down.)\n",
      "io.fabric8.kubernetes.client.WatcherException: too old resource version: 94456657 (94457751)\n",
      "\tat io.fabric8.kubernetes.client.dsl.internal.AbstractWatchManager.onStatus(AbstractWatchManager.java:265)\n",
      "\tat io.fabric8.kubernetes.client.dsl.internal.AbstractWatchManager.onMessage(AbstractWatchManager.java:249)\n",
      "\tat io.fabric8.kubernetes.client.dsl.internal.WatcherWebSocketListener.onMessage(WatcherWebSocketListener.java:93)\n",
      "\tat okhttp3.internal.ws.RealWebSocket.onReadMessage(RealWebSocket.java:323)\n",
      "\tat okhttp3.internal.ws.WebSocketReader.readMessageFrame(WebSocketReader.java:219)\n",
      "\tat okhttp3.internal.ws.WebSocketReader.processNextFrame(WebSocketReader.java:105)\n",
      "\tat okhttp3.internal.ws.RealWebSocket.loopReader(RealWebSocket.java:274)\n",
      "\tat okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:214)\n",
      "\tat okhttp3.RealCall$AsyncCall.execute(RealCall.java:203)\n",
      "\tat okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: io.fabric8.kubernetes.client.KubernetesClientException: too old resource version: 94456657 (94457751)\n",
      "\t... 13 more\n",
      "24/01/24 15:54:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:54:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:55:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:55:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:55:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:55:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:56:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:56:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/01/24 15:56:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "[Stage 2:===========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+---------------------+\n",
      "|        RUT_SOCIEDAD|           RUT_SOCIO|PORCENTAJE_CAPITAL|PORCENTAJE_UTILIDADES|\n",
      "+--------------------+--------------------+------------------+---------------------+\n",
      "|+++JjoAr1RQa1kY7r...|S2zsiazT64Jiu/sSE...|             85.71|                85.71|\n",
      "|+++JjoAr1RQa1kY7r...|xO5P1s+Yeug4wKtb8...|             14.29|                14.29|\n",
      "|+++P6tU1TAUNG0SZv...|8ejqjUOvnKKfMZSzj...|             100.0|                100.0|\n",
      "|+++UeiptXaAQD74N1...|5jgmhcvBN2sVp7Gh5...|              72.0|                 72.0|\n",
      "|+++UeiptXaAQD74N1...|QemGi6c6gkD3rdstn...|              28.0|                 28.0|\n",
      "|+++VKgYcn1igYZjkT...|XRkbvgfaa5MRVblDF...|             100.0|                100.0|\n",
      "|+++VWXcqX/471v55m...|d/Gh1G45HEItM+byD...|              99.0|                 99.0|\n",
      "|+++VWXcqX/471v55m...|t9AEh7tBjjp3FKWzm...|               1.0|                  1.0|\n",
      "|+++ZYfC4XA28yQEQd...|Rf14vs+327ZlNsQvX...|             100.0|                100.0|\n",
      "|+++rmzjqUcW56fKfV...|/SogFhjTgxloEfGYI...|              47.5|                 47.5|\n",
      "|+++rmzjqUcW56fKfV...|VULdXIkUAxKz8BFIA...|              52.5|                 52.5|\n",
      "|++/BNOl5Jzp3/53dg...|vkzKrESk+2mIrPN2k...|              20.0|                 20.0|\n",
      "|++/BNOl5Jzp3/53dg...|ymLFBcIElT/XLhLlT...|              80.0|                 80.0|\n",
      "|++/ILpGAKOZrH+0u+...|K3BDtZLATzJK/u2xk...|              50.0|                 50.0|\n",
      "|++/ILpGAKOZrH+0u+...|VSDSGFi3SI0jGmj/Z...|              50.0|                 50.0|\n",
      "|++/O0DVO8dUreJB37...|7xFbJHM0rhVJe4iga...|              99.0|                 99.0|\n",
      "|++/O0DVO8dUreJB37...|M5Es6UQcBIdMrEARV...|               1.0|                  1.0|\n",
      "|++/UTl2mwL/J484yK...|LxuWEPpbFk7A2Iind...|             100.0|                100.0|\n",
      "|++/dFaxQQDYaKe8zO...|ZvW38n/QbAl+aaQwJ...|              50.0|                 50.0|\n",
      "|++/dFaxQQDYaKe8zO...|lQ+jywhdl+H43AHiw...|              50.0|                 50.0|\n",
      "+--------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header=True,inferSchema=True,delimiter=\",\").csv(\"../../data/processed/sociedades_participacion_capital_nozero.csv\")\n",
    "df.createOrReplaceTempView(\"sociedad\")\n",
    "spark.sql(\"select * from sociedad order by RUT_SOCIEDAD asc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae6b7f-58e7-4902-98b9-4c35f2e0d3c1",
   "metadata": {},
   "source": [
    "## Exploracion de composiciones de socios en capital y utilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525a1d8-7a44-4b91-bc32-bd41bd85d0da",
   "metadata": {},
   "source": [
    "Como no hay unicidad de entradas y se puede presentar varias veces una combinacion sociedad y socio, se agrupa por el promedio para cada relacion. De esta forma analizamos la composicion de la sociedad en utilidades y capital.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6566477-7700-42a3-8cd4-bb0130c15f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select  RUT_SOCIEDAD, RUT_SOCIO, mean(PORCENTAJE_CAPITAL) as PORCENTAJE_CAPITAL, mean(PORCENTAJE_UTILIDADES) as PORCENTAJE_UTILIDADES from sociedad group by RUT_SOCIEDAD, RUT_SOCIO\").createOrReplaceTempView(\"composicion\")\n",
    "spark.sql(\"select  RUT_SOCIEDAD, sum(PORCENTAJE_CAPITAL) as TOTAL_CAPITAL, SUM(PORCENTAJE_UTILIDADES) as TOTAL_UTILIDADES from composicion group by RUT_SOCIEDAD\").createOrReplaceTempView(\"composicion\")\n",
    "m=spark.sql(\"select * from composicion\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de28ea0-245e-4e29-a7fd-f406175769f3",
   "metadata": {},
   "source": [
    "Veamos cuantas sociedades suman mas del 100% en capital total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d172ffc3-9254-4949-8351-3ac957ebcfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUT_SOCIEDAD</th>\n",
       "      <th>TOTAL_CAPITAL</th>\n",
       "      <th>TOTAL_UTILIDADES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36604</th>\n",
       "      <td>qBN0Ew2XbPgKTj0PyLtzcA==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42282</th>\n",
       "      <td>+yO9yJXI/gw9x7dec0Lt+A==</td>\n",
       "      <td>105.70</td>\n",
       "      <td>124.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44850</th>\n",
       "      <td>0XuN90P2eQMydmKE9OW64Q==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50997</th>\n",
       "      <td>W62rStOCYMtosUOwv5LBgA==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60060</th>\n",
       "      <td>zJLdRqdwJgz4dtWd9xh1Lg==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346933</th>\n",
       "      <td>PpKVd7x+KKrDzssyhs0TAw==</td>\n",
       "      <td>106.78</td>\n",
       "      <td>106.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349357</th>\n",
       "      <td>qyJdWYK0NpWG7WDVPw2igQ==</td>\n",
       "      <td>109.00</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352093</th>\n",
       "      <td>p8AtykYwPslwpOXSkRODLQ==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372894</th>\n",
       "      <td>MqkQRluUHZIXHZlneEoJsQ==</td>\n",
       "      <td>109.00</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386587</th>\n",
       "      <td>0cT8llyE0hI5AOU2GCtycg==</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RUT_SOCIEDAD  TOTAL_CAPITAL  TOTAL_UTILIDADES\n",
       "36604    qBN0Ew2XbPgKTj0PyLtzcA==         110.00             74.00\n",
       "42282    +yO9yJXI/gw9x7dec0Lt+A==         105.70            124.99\n",
       "44850    0XuN90P2eQMydmKE9OW64Q==         110.00            110.00\n",
       "50997    W62rStOCYMtosUOwv5LBgA==         110.00            110.00\n",
       "60060    zJLdRqdwJgz4dtWd9xh1Lg==         110.00            110.00\n",
       "...                           ...            ...               ...\n",
       "1346933  PpKVd7x+KKrDzssyhs0TAw==         106.78            106.78\n",
       "1349357  qyJdWYK0NpWG7WDVPw2igQ==         109.00            109.00\n",
       "1352093  p8AtykYwPslwpOXSkRODLQ==         110.00            100.00\n",
       "1372894  MqkQRluUHZIXHZlneEoJsQ==         109.00            109.00\n",
       "1386587  0cT8llyE0hI5AOU2GCtycg==         110.00            110.00\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[m['TOTAL_CAPITAL']>105] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27940576-24f4-4a9c-9f4e-55216596dd2f",
   "metadata": {},
   "source": [
    "Veamos cuantas sociedades suman menos de 90% en capital total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77d53244-7013-4119-b3f4-255d0f1ec29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUT_SOCIEDAD</th>\n",
       "      <th>TOTAL_CAPITAL</th>\n",
       "      <th>TOTAL_UTILIDADES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681087</th>\n",
       "      <td>015/V4NMbTt4NqHquyzHAQ==</td>\n",
       "      <td>11.29</td>\n",
       "      <td>11.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RUT_SOCIEDAD  TOTAL_CAPITAL  TOTAL_UTILIDADES\n",
       "681087  015/V4NMbTt4NqHquyzHAQ==          11.29             11.29"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[m['TOTAL_CAPITAL']<90] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3a24093-eaac-4d00-8d7e-518493ba144e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUT_SOCIEDAD</th>\n",
       "      <th>TOTAL_CAPITAL</th>\n",
       "      <th>TOTAL_UTILIDADES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17087</th>\n",
       "      <td>y2vuFSg0i2sqmpg4ayJ4LQ==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>OdNW1enN1u4LwpLOpweOTQ==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35745</th>\n",
       "      <td>AFT7+4VOTHnj2AQ4V7HRjA==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36635</th>\n",
       "      <td>3pZ4jwIjTPhgr9SFW72W9g==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>145.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42282</th>\n",
       "      <td>+yO9yJXI/gw9x7dec0Lt+A==</td>\n",
       "      <td>105.7</td>\n",
       "      <td>124.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349357</th>\n",
       "      <td>qyJdWYK0NpWG7WDVPw2igQ==</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369174</th>\n",
       "      <td>7oq5WRip3ZmPavK3AkWR/A==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>154.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371285</th>\n",
       "      <td>vGFtt5wSI+ZAORZgj9Fs/w==</td>\n",
       "      <td>100.0</td>\n",
       "      <td>145.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372894</th>\n",
       "      <td>MqkQRluUHZIXHZlneEoJsQ==</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386587</th>\n",
       "      <td>0cT8llyE0hI5AOU2GCtycg==</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RUT_SOCIEDAD  TOTAL_CAPITAL  TOTAL_UTILIDADES\n",
       "17087    y2vuFSg0i2sqmpg4ayJ4LQ==          100.0            109.00\n",
       "32084    OdNW1enN1u4LwpLOpweOTQ==          100.0            120.00\n",
       "35745    AFT7+4VOTHnj2AQ4V7HRjA==          100.0            109.00\n",
       "36635    3pZ4jwIjTPhgr9SFW72W9g==          100.0            145.00\n",
       "42282    +yO9yJXI/gw9x7dec0Lt+A==          105.7            124.99\n",
       "...                           ...            ...               ...\n",
       "1349357  qyJdWYK0NpWG7WDVPw2igQ==          109.0            109.00\n",
       "1369174  7oq5WRip3ZmPavK3AkWR/A==          100.0            154.00\n",
       "1371285  vGFtt5wSI+ZAORZgj9Fs/w==          100.0            145.00\n",
       "1372894  MqkQRluUHZIXHZlneEoJsQ==          109.0            109.00\n",
       "1386587  0cT8llyE0hI5AOU2GCtycg==          110.0            110.00\n",
       "\n",
       "[164 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[m['TOTAL_UTILIDADES']>105] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fcd8003-a8e3-41d7-9f97-0c9f4cf59ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUT_SOCIEDAD</th>\n",
       "      <th>TOTAL_CAPITAL</th>\n",
       "      <th>TOTAL_UTILIDADES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kqvmxZXKear6P8xAR3GXVg==</td>\n",
       "      <td>90.00</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>7/JzC/njmhl4xZ3D1Z/lcA==</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>GOXX0rDaK+eR0lyod51xsg==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>QwJ3CJDviryxVP6pVxuTaA==</td>\n",
       "      <td>100.01</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>IRrJwtGlTFSYlh/9OmkSbA==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388254</th>\n",
       "      <td>mHXs6IbCeQvL1KVfYly91g==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388722</th>\n",
       "      <td>MGStvbYH0J++QOqIDvrmsw==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389016</th>\n",
       "      <td>denpwjejwcf3nzG0fJqwvQ==</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389452</th>\n",
       "      <td>LFSUoUnGK/OcQf/9cZN3cg==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389604</th>\n",
       "      <td>vhIUf0QcLW0LnpoKWx6unQ==</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RUT_SOCIEDAD  TOTAL_CAPITAL  TOTAL_UTILIDADES\n",
       "30       kqvmxZXKear6P8xAR3GXVg==          90.00              90.0\n",
       "378      7/JzC/njmhl4xZ3D1Z/lcA==          94.00              94.0\n",
       "814      GOXX0rDaK+eR0lyod51xsg==         100.00              60.0\n",
       "1194     QwJ3CJDviryxVP6pVxuTaA==         100.01              90.0\n",
       "1908     IRrJwtGlTFSYlh/9OmkSbA==         100.00              93.3\n",
       "...                           ...            ...               ...\n",
       "1388254  mHXs6IbCeQvL1KVfYly91g==         100.00              50.0\n",
       "1388722  MGStvbYH0J++QOqIDvrmsw==         100.00              50.0\n",
       "1389016  denpwjejwcf3nzG0fJqwvQ==          91.00              91.0\n",
       "1389452  LFSUoUnGK/OcQf/9cZN3cg==         100.00              50.0\n",
       "1389604  vhIUf0QcLW0LnpoKWx6unQ==         100.00              50.0\n",
       "\n",
       "[1426 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[m['TOTAL_UTILIDADES']<95] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99d892-b290-427d-8fbf-5c9fed789d08",
   "metadata": {},
   "source": [
    "Se utilizara el porcentaje de capital en lugar de utilidades para hacer la transmision de materia oscura. En el proceso de limpieza de datos se considero las filas con valores no nuels de PORCENTAJE_CAPITAL. Se utilizara una tabla de composicion para poder normalizar los valores de oscuridad para cuando los valores de porcentajes se capital sean diferentes al 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ad2f5-bee7-49c8-be82-7bb3bc15863f",
   "metadata": {},
   "source": [
    "## Tabla de ponderacion para el total de capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac4d09c2-58cc-4859-8f1c-bf19041d7bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select RUT_SOCIEDAD as CONT_RUT, TOTAL_CAPITAL as ponderador from composicion\").createOrReplaceTempView(\"composicion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5c658-62c5-43ae-82e5-4b705e33ed6c",
   "metadata": {},
   "source": [
    "## Lectura de tabla de oscuridad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b429b-382d-471d-8076-4e8041876575",
   "metadata": {},
   "source": [
    "Se hace lectura de los datos de iniciales de oscuridad para personas naturales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbb80a48-998a-4a55-a125-1704471b2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            CONT_RUT|       Valor|\n",
      "+--------------------+------------+\n",
      "|+++++jqhSCxb4MYni...|0.2505881216|\n",
      "|++++4VUrSBUBG/m/C...|0.2505881216|\n",
      "|++++LbywbfVQJ4b6r...|         1.0|\n",
      "|++++mpym73swtBJsE...|0.2505881216|\n",
      "|+++/mtz2Y6dR0yWCY...|0.2505881216|\n",
      "|+++0Pn3sll6VwPH5U...|0.2505881216|\n",
      "|+++0Re2TkLe14DpcD...|0.2505881216|\n",
      "|+++1gCGSMhlEHLJDQ...|         1.0|\n",
      "|+++1iAkZoVFs4IYW1...|0.2505881216|\n",
      "|+++21EA/iuTO4I/ht...|0.2505881216|\n",
      "|+++2MYr/KzH2JhNCN...|         1.0|\n",
      "|+++40fb1kG88W0AEf...|         1.0|\n",
      "|+++4Na3wJ7SIFPhPQ...|         1.0|\n",
      "|+++58HnadEZ4X4kXn...|         1.0|\n",
      "|+++5xuy9R938QLB66...|0.7911765654|\n",
      "|+++69H052vRRRkQ54...|0.2505881216|\n",
      "|+++6Pf94vKHoUDM+E...|0.2505881216|\n",
      "|+++7gCpP/p5z+drab...|0.3512938674|\n",
      "|+++86Ho6cZD74hGWy...|         1.0|\n",
      "|+++Aa4Gv7OgWPwQ6p...|0.6809641971|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oscuridad1=spark.sql(\"select * from libsdf.jab_materia_inom\")\n",
    "oscuridad1.createOrReplaceTempView(\"oscuridad\")\n",
    "spark.sql(\"select * from oscuridad order by Valos asc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2900a1-6a01-423e-8947-726f858a056a",
   "metadata": {},
   "source": [
    "## Ajuste de valores de participacion societaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069c3e3-1c39-49fa-afd0-dfec4149db82",
   "metadata": {
    "tags": []
   },
   "source": [
    "Como para una combinacion sociedad socio tenemos distintos valores de PORCENTAJE_CAPITAL y PORCENTAJE_UTILIDADES se usara el promedio de dichos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74c92081-ea0e-4481-bcd4-82d2a0ac48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select  RUT_SOCIEDAD, RUT_SOCIO, mean(PORCENTAJE_CAPITAL) as PORCENTAJE_CAPITAL, mean(PORCENTAJE_UTILIDADES) as PORCENTAJE_UTILIDADES from sociedad group by RUT_SOCIEDAD, RUT_SOCIO\").createOrReplaceTempView(\"sociedad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30327b42-d1a6-4940-a7a8-4f1b32b1990c",
   "metadata": {},
   "source": [
    "## Primera iteracion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aba72c-5ad9-4511-9c2b-d46cd2b38979",
   "metadata": {},
   "source": [
    "Se realiza el cruce de la data societaria con la data de  oscuridad de personas naturales (1re paso de calculo de materia oscura para sociedades completas). Para ello se completa la malla con la oscuridad inicial. Hay sociedades donde no se completan todos los socios con oscuridad, por lo cual se discrimina mediante un contador de nulos de dicho campo para poder agregar la data y obtener un valor de oscuridad para un rut de soiedad donde todas las entradas de sus socios han sido completadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6119d26-ce3e-4eb1-94f3-dc7e1e7acc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iteracion 0\n",
    "spark.sql(\"select * from sociedad left join oscuridad on sociedad.RUT_SOCIO=oscuridad.CONT_RUT order by sociedad.RUT_SOCIEDAD asc\").createOrReplaceTempView(\"sociedad\")\n",
    "#spark.sql(\"select * from sociedad \").show()\n",
    "spark.sql(\"select RUT_SOCIEDAD, RUT_SOCIO, PORCENTAJE_CAPITAL, Valor from sociedad\").createOrReplaceTempView(\"sociedad\")\n",
    "#spark.sql(\"select * from sociedad \").show()\n",
    "spark.sql(\"select RUT_SOCIEDAD as RUT_SOCIEDAD1, count(*) as nulos  from sociedad where Valor is null group by RUT_SOCIEDAD order by RUT_SOCIEDAD ASC\").createOrReplaceTempView(\"aux\")\n",
    "#spark.sql(\"select * from aux \").show()\n",
    "spark.sql(\"select RUT_SOCIEDAD,RUT_SOCIO,PORCENTAJE_CAPITAL, nulos, Valor from sociedad left join aux on sociedad.RUT_SOCIEDAD=aux.RUT_SOCIEDAD1 order by RUT_SOCIEDAD asc \").createOrReplaceTempView(\"aux\")\n",
    "#spark.sql(\"select * from aux where nulos is null \").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7f9d4-53f6-47ce-a10c-ea78ca7abcc2",
   "metadata": {},
   "source": [
    "## Primera iteracion, cruce con oscuridad de personas naturales (2do paso de calculo de oscuridad y ponderacion por total de capital)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814edd68-6c1e-442a-b625-1546d1265a77",
   "metadata": {},
   "source": [
    "Junto con completar la data con los valores de oscuridad para sociedades completas, se agrega un ponderador. De esta forma, si una entidad tiene dos socios con oscuridad y la composicion suma diferente a 100%, se pondera proporcionalmente para que sumen 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb33403d-c544-4306-a259-0a4a54b4f5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "#agregar a la oscuridad la ponderacion adecuada\n",
    "\n",
    "spark.sql(\"select RUT_SOCIEDAD,RUT_SOCIO,PORCENTAJE_CAPITAL, Valor from aux where nulos is null\").createOrReplaceTempView(\"aux\")\n",
    "#spark.sql(\"select * from aux\").show()\n",
    "spark.sql(\"select RUT_SOCIEDAD as CONT_RUT, SUM(PORCENTAJE_CAPITAL*Valor*0.01) as othervalue from aux group by RUT_SOCIEDAD\").createOrReplaceTempView(\"oscuridad\")\n",
    "#spark.sql(\"select * from oscuridad\").show()\n",
    "spark.sql(\"select CONT_RUT, othervalue as Value from oscuridad\").createOrReplaceTempView(\"oscuridad\")\n",
    "#spark.sql(\"select * from oscuridad\").show()\n",
    "\n",
    "spark.sql(\"select oscuridad.CONT_RUT as CONT_RUT, Value, ponderador from oscuridad left join composicion on oscuridad.CONT_RUT=composicion.CONT_RUT order by oscuridad.CONT_RUT desc \").createOrReplaceTempView(\"oscuridad\")\n",
    "#spark.sql(\"select * from oscuridad \").show()\n",
    "spark.sql(\"select CONT_RUT, Value/ponderador*100 as Value from oscuridad \").createOrReplaceTempView(\"oscuridad\")\n",
    "#spark.sql(\"select * from oscuridad order by Value desc \").show()\n",
    "\n",
    "#spark.sql(\"select RUT_SOCIEDAD,RUT_SOCIO,PORCENTAJE_UTILIDADES, Valor from aux where nulos is null\").createOrReplaceTempView(\"aux\")\n",
    "\n",
    "oscuridad_aux=spark.sql(\"select * from oscuridad \").toPandas()\n",
    "oscuridad_aux['iterations']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18fb6f10-1860-4a86-82c1-3a5fcfad04ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONT_RUT</th>\n",
       "      <th>Value</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzzo7RUe8Wp/sBVZrqC1BQ==</td>\n",
       "      <td>0.235367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzzEfsBUrus3+LpvpwcHig==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzz9RqdyHZm0pUPELnEPhw==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzz0aRgQrVHwDX+AyZc8SQ==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzydn/q5KUdW0PcyxWSyzg==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284452</th>\n",
       "      <td>+++VWXcqX/471v55mS2YiA==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284453</th>\n",
       "      <td>+++VKgYcn1igYZjkTHXjgA==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284454</th>\n",
       "      <td>+++UeiptXaAQD74N1rCuIg==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284455</th>\n",
       "      <td>+++P6tU1TAUNG0SZvJeW6w==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284456</th>\n",
       "      <td>+++JjoAr1RQa1kY7rIZbFg==</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         CONT_RUT     Value  iterations\n",
       "0        zzzo7RUe8Wp/sBVZrqC1BQ==  0.235367           0\n",
       "1        zzzEfsBUrus3+LpvpwcHig==  0.250588           0\n",
       "2        zzz9RqdyHZm0pUPELnEPhw==  0.250588           0\n",
       "3        zzz0aRgQrVHwDX+AyZc8SQ==  0.250588           0\n",
       "4        zzydn/q5KUdW0PcyxWSyzg==  0.250588           0\n",
       "...                           ...       ...         ...\n",
       "1284452  +++VWXcqX/471v55mS2YiA==  0.250588           0\n",
       "1284453  +++VKgYcn1igYZjkTHXjgA==  0.250588           0\n",
       "1284454  +++UeiptXaAQD74N1rCuIg==  0.250588           0\n",
       "1284455  +++P6tU1TAUNG0SZvJeW6w==  0.250588           0\n",
       "1284456  +++JjoAr1RQa1kY7rIZbFg==  0.250588           0\n",
       "\n",
       "[1284457 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscuridad_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47690c62-4f5b-483e-9a42-7ca293966bcc",
   "metadata": {},
   "source": [
    "## Primera iteracion,resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408910b2-acc3-4350-a424-afb764799a96",
   "metadata": {},
   "source": [
    "Principales resultados de la primera iteracion, es decir la iteracion cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d15b6f-2e7c-40f8-ab00-8761d7612d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oscuridad_aux.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b95ca-1981-4d91-8cea-b512fd90ed15",
   "metadata": {},
   "source": [
    "## Iteraciones subsiguientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5d898-475c-4763-ba7a-d03874002399",
   "metadata": {},
   "source": [
    "Se repite el proceso iterativo para asi completar mas sociedades. El parametro *iter* hara referencia al numero de iteraciones luego de la iteracion 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ac65b-38bb-4da5-af4b-9d34202426c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345a968-456f-433b-93bb-b71485505b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for iteration in range(1,iter):\n",
    "    \n",
    "    spark.sql(\"select * from sociedad left join oscuridad on sociedad.RUT_SOCIO=oscuridad.CONT_RUT order by sociedad.RUT_SOCIEDAD asc\").createOrReplaceTempView(\"sociedad\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD, RUT_SOCIO, PORCENTAJE_CAPITAL, CASE WHEN Valor is null THEN Value ELSE Valor END AS Valor from sociedad\").createOrReplaceTempView(\"sociedad\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD, RUT_SOCIO, PORCENTAJE_CAPITAL, Valor from sociedad\").createOrReplaceTempView(\"sociedad\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD as RUT_SOCIEDAD1, count(*) as nulos from sociedad where Valor is null group by RUT_SOCIEDAD order by RUT_SOCIEDAD ASC\").createOrReplaceTempView(\"aux\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD,RUT_SOCIO,PORCENTAJE_CAPITAL, nulos, Valor from sociedad left join aux on sociedad.RUT_SOCIEDAD=aux.RUT_SOCIEDAD1 order by RUT_SOCIEDAD asc \").createOrReplaceTempView(\"aux\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD,RUT_SOCIO,PORCENTAJE_CAPITAL, Valor from aux where nulos is null\").createOrReplaceTempView(\"aux\")\n",
    "    spark.sql(\"select RUT_SOCIEDAD as CONT_RUT, SUM(PORCENTAJE_CAPITAL*Valor*0.01) as othervalue from aux group by RUT_SOCIEDAD\").createOrReplaceTempView(\"oscuridad\")\n",
    "    spark.sql(\"select CONT_RUT, othervalue as Value from oscuridad\").createOrReplaceTempView(\"oscuridad\")\n",
    "    \n",
    "    spark.sql(\"select oscuridad.CONT_RUT as CONT_RUT, Value,ponderador from oscuridad left join composicion on oscuridad.CONT_RUT=composicion.CONT_RUT order by oscuridad.CONT_RUT asc \").createOrReplaceTempView(\"oscuridad\")\n",
    "    #spark.sql(\"select * from oscuridad \").show()\n",
    "    spark.sql(\"select CONT_RUT, Value/ponderador*100 as Value from oscuridad order by Value desc \").createOrReplaceTempView(\"oscuridad\")\n",
    "    #spark.sql(\"select * from oscuridad \").show()    \n",
    "    oscuridad=spark.sql(\"select * from oscuridad \").toPandas()\n",
    "    oscuridad['iterations']=iteration\n",
    "\n",
    "    oscuridad=oscuridad.merge(oscuridad_aux, on = \"CONT_RUT\", how = \"left\")\n",
    "    oscuridad['iterations']=oscuridad[[\"iterations_x\", \"iterations_y\"]].min(axis=1)\n",
    "    oscuridad = oscuridad.rename(columns={'Value_x': 'Value'})\n",
    "    oscuridad=oscuridad[['CONT_RUT','Value','iterations']]\n",
    "    oscuridad_aux=oscuridad.iloc[:,:]\n",
    "    print(oscuridad_aux.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961b02f-b7cc-4553-93a4-b7490a1e3394",
   "metadata": {},
   "source": [
    "## Resultados y guardado en archivo csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01371a-9f7d-4712-aa22-87cfc55408e2",
   "metadata": {},
   "source": [
    "Luego de estas iteraciones, se obtienen dos outputs. En primer lugar una tabla actualizada de sociedades y socios con cada valor calculado (o no) de la oscuridad de sus socios. \n",
    "En segundo lugar la oscuridad calculada para sociedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386716f6-d292-4429-9bb9-c3ed33121f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sociedad=spark.sql(\"select * from sociedad\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5df80e-65bb-4b82-b484-8cc88129bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guardan los archivos finales.\n",
    "sociedad.to_csv('artefactos/Oscuridad/Sociedades_oscuridad_actualizada.csv', index=False)\n",
    "oscuridad_aux.to_csv('artefactos/Oscuridad/Sociedades_oscuridad_completa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6968f-edf7-4509-9392-a3f1c2f6cef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
